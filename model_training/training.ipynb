{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d16b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a99a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Concatenate, UpSampling2D, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Kiểm tra xem TensorFlow có nhận GPU không (để train nhanh hơn)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21097923",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioH5Generator(Sequence):\n",
    "    def __init__(self, h5_path, list_IDs, batch_size=16, shuffle=True):\n",
    "        \"\"\"\n",
    "        h5_path: Đường dẫn tới file data_2d.h5\n",
    "        list_IDs: Danh sách các index (số thứ tự) mẫu sẽ dùng (để chia train/val)\n",
    "        batch_size: Kích thước lô (giảm xuống nếu vẫn bị tràn VRAM GPU)\n",
    "        \"\"\"\n",
    "        self.h5_path = h5_path\n",
    "        self.list_IDs = list_IDs\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        # Tính số lượng batch trong 1 epoch\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Lấy ra danh sách index cho batch hiện tại\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Gọi hàm lấy dữ liệu thực tế\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Xáo trộn dữ liệu sau mỗi epoch\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        # Mở file H5\n",
    "        with h5py.File(self.h5_path, 'r') as f:\n",
    "            # Lấy Dataset\n",
    "            X_dset = f['X_train']\n",
    "            Y_dset = f['Y_train']\n",
    "\n",
    "            # Cách 1: Dùng List Comprehension (An toàn nhất)\n",
    "            # Duyệt qua từng ID trong batch và lấy dữ liệu từng cái một\n",
    "            # h5py hỗ trợ rất tốt việc lấy đơn lẻ f['X_train'][10]\n",
    "            X_batch = [X_dset[int(ID)] for ID in list_IDs_temp]\n",
    "            y_batch = [Y_dset[int(ID)] for ID in list_IDs_temp]\n",
    "\n",
    "        # Chuyển list thành numpy array để trả về cho Model\n",
    "        return np.array(X_batch), np.array(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dc513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../media_files/preprocessed_audio/data_2d.h5'\n",
    "BATCH_SIZE = 16 # Nếu GPU yếu (như GTX 1650/1050), hãy giảm xuống 8 hoặc 4\n",
    "\n",
    "# 1. Mở file để xem tổng số mẫu\n",
    "with h5py.File(DATA_PATH, 'r') as f:\n",
    "    total_samples = f['X_train'].shape[0]\n",
    "    input_shape = f['X_train'].shape[1:] # (1024, 128, 1)\n",
    "    print(f\"Tổng số mẫu dữ liệu: {total_samples}\")\n",
    "    print(f\"Kích thước đầu vào: {input_shape}\")\n",
    "\n",
    "# 2. Tạo danh sách ID và chia Train/Val (80% Train, 20% Val)\n",
    "all_indices = np.arange(total_samples)\n",
    "train_ids, val_ids = train_test_split(all_indices, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Số mẫu Train: {len(train_ids)}\")\n",
    "print(f\"Số mẫu Val: {len(val_ids)}\")\n",
    "\n",
    "# 3. Khởi tạo Generators\n",
    "training_generator = AudioH5Generator(DATA_PATH, train_ids, batch_size=BATCH_SIZE)\n",
    "validation_generator = AudioH5Generator(DATA_PATH, val_ids, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c4b8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # --- ENCODER ---\n",
    "    # Block 1\n",
    "    c1 = Conv2D(16, (3, 3), padding='same', activation='relu')(inputs)\n",
    "    c1 = BatchNormalization()(c1)\n",
    "    c1 = Conv2D(16, (3, 3), padding='same', activation='relu')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    # Block 2\n",
    "    c2 = Conv2D(32, (3, 3), padding='same', activation='relu')(p1)\n",
    "    c2 = BatchNormalization()(c2)\n",
    "    c2 = Conv2D(32, (3, 3), padding='same', activation='relu')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    # Block 3\n",
    "    c3 = Conv2D(64, (3, 3), padding='same', activation='relu')(p2)\n",
    "    c3 = BatchNormalization()(c3)\n",
    "    c3 = Conv2D(64, (3, 3), padding='same', activation='relu')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    \n",
    "    # Block 4\n",
    "    c4 = Conv2D(128, (3, 3), padding='same', activation='relu')(p3)\n",
    "    c4 = BatchNormalization()(c4)\n",
    "    c4 = Conv2D(128, (3, 3), padding='same', activation='relu')(c4)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    # --- BOTTLENECK ---\n",
    "    b = Conv2D(256, (3, 3), padding='same', activation='relu')(p4)\n",
    "    b = BatchNormalization()(b)\n",
    "    b = Conv2D(256, (3, 3), padding='same', activation='relu')(b)\n",
    "\n",
    "    # --- DECODER ---\n",
    "    # Block 4 Up\n",
    "    u1 = UpSampling2D((2, 2))(b)\n",
    "    u1 = Concatenate()([u1, c4])\n",
    "    c5 = Conv2D(128, (3, 3), padding='same', activation='relu')(u1)\n",
    "    c5 = BatchNormalization()(c5)\n",
    "    \n",
    "    # Block 3 Up\n",
    "    u2 = UpSampling2D((2, 2))(c5)\n",
    "    u2 = Concatenate()([u2, c3])\n",
    "    c6 = Conv2D(64, (3, 3), padding='same', activation='relu')(u2)\n",
    "    c6 = BatchNormalization()(c6)\n",
    "\n",
    "    # Block 2 Up\n",
    "    u3 = UpSampling2D((2, 2))(c6)\n",
    "    u3 = Concatenate()([u3, c2])\n",
    "    c7 = Conv2D(32, (3, 3), padding='same', activation='relu')(u3)\n",
    "    c7 = BatchNormalization()(c7)\n",
    "    \n",
    "    # Block 1 Up\n",
    "    u4 = UpSampling2D((2, 2))(c7)\n",
    "    u4 = Concatenate()([u4, c1])\n",
    "    c8 = Conv2D(16, (3, 3), padding='same', activation='relu')(u4)\n",
    "    c8 = BatchNormalization()(c8)\n",
    "\n",
    "    # Output (Sigmoid cho mask 0-1)\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c8)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "model = build_unet(input_shape)\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a688b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint: Chỉ lưu model khi validation loss giảm (Model tốt nhất)\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_unet_vocal.keras', # Đuôi .keras là chuẩn mới của TensorFlow\n",
    "    monitor='val_loss', \n",
    "    verbose=1, \n",
    "    save_best_only=True, \n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# ReduceLR: Giảm learning rate nếu loss không giảm sau 3 epochs (giúp hội tụ sâu hơn)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.2, \n",
    "    patience=3, \n",
    "    min_lr=1e-6, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# EarlyStopping: Dừng train nếu loss không giảm sau 5 epochs (tránh tốn điện)\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5, \n",
    "    verbose=1, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# BẮT ĐẦU TRAIN\n",
    "history = model.fit(\n",
    "    training_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=50, # Đặt nhiều, EarlyStopping sẽ lo việc dừng sớm\n",
    "    callbacks=[checkpoint, reduce_lr, early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7f5c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Accuracy Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826447e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy 1 batch từ tập validation để test\n",
    "X_test, y_test = validation_generator[0]\n",
    "\n",
    "# Dự đoán\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Vẽ 3 hình: Input Mix, True Mask, Predicted Mask\n",
    "def visualize_sample(index):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # 1. Input Spectrogram (Mix)\n",
    "    plt.subplot(1, 3, 1)\n",
    "    # Xoay ngược trục Y (origin='lower') để tần số thấp ở dưới\n",
    "    plt.imshow(X_test[index, :, :, 0], aspect='auto', origin='lower', cmap='magma')\n",
    "    plt.title(\"Input Mixture Spectrogram\")\n",
    "    \n",
    "    # 2. True Mask (Vocal gốc)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(y_test[index, :, :, 0], aspect='auto', origin='lower', cmap='gray')\n",
    "    plt.title(\"Ground Truth Vocal Mask\")\n",
    "    \n",
    "    # 3. Predicted Mask (Model dự đoán)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(y_pred[index, :, :, 0], aspect='auto', origin='lower', cmap='gray')\n",
    "    plt.title(\"Predicted Vocal Mask\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Hiển thị kết quả của mẫu thứ 0 và mẫu thứ 5 trong batch\n",
    "visualize_sample(0)\n",
    "visualize_sample(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
