{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71935ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Concatenate, UpSampling2D, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import soundfile as sf\n",
    "\n",
    "# Kiểm tra GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553c6d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CẤU HÌNH ---\n",
    "# Đường dẫn file dữ liệu train (đã tạo từ bước preprocessing)\n",
    "DATA_PATH = '../media_files/preprocessed_audio/data_2d.h5'\n",
    "\n",
    "# Đường dẫn file nhạc để đánh giá (visualize) sau mỗi epoch\n",
    "# BẠN CẦN THAY ĐỔI ĐƯỜNG DẪN NÀY TỚI 1 FILE NHẠC THỰC TẾ\n",
    "EVALUATION_PATH = '../media_files/test_audio/test_song.wav' \n",
    "\n",
    "# Thư mục lưu ảnh visualize\n",
    "OUTPUT_VISUAL_DIR = 'training_visualizations'\n",
    "os.makedirs(OUTPUT_VISUAL_DIR, exist_ok=True)\n",
    "\n",
    "# Tham số âm thanh (Phải khớp với file preprocessing)\n",
    "BATCH_SIZE = 16\n",
    "SR = 44100\n",
    "WINDOW_SIZE = 128\n",
    "N_FFT = 2048\n",
    "HOP_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028f468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioH5Generator(Sequence):\n",
    "    def __init__(self, h5_path, list_IDs, batch_size=16, shuffle=True):\n",
    "        self.h5_path = h5_path\n",
    "        self.list_IDs = list_IDs\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        with h5py.File(self.h5_path, 'r') as f:\n",
    "            X_dset = f['X_train']\n",
    "            Y_dset = f['Y_train']\n",
    "            # Dùng list comprehension để lấy data an toàn\n",
    "            X_batch = [X_dset[int(ID)] for ID in list_IDs_temp]\n",
    "            y_batch = [Y_dset[int(ID)] for ID in list_IDs_temp]\n",
    "        return np.array(X_batch), np.array(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb55fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Mở file để xem tổng số mẫu\n",
    "with h5py.File(DATA_PATH, 'r') as f:\n",
    "    total_samples = f['X_train'].shape[0]\n",
    "    input_shape = f['X_train'].shape[1:] # (1024, 128, 1)\n",
    "    print(f\"Tổng số mẫu dữ liệu: {total_samples}\")\n",
    "    print(f\"Kích thước đầu vào: {input_shape}\")\n",
    "\n",
    "# 2. Chia Train/Val (80% Train, 20% Val)\n",
    "all_indices = np.arange(total_samples)\n",
    "train_ids, val_ids = train_test_split(all_indices, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Số mẫu Train: {len(train_ids)}\")\n",
    "print(f\"Số mẫu Val: {len(val_ids)}\")\n",
    "\n",
    "# 3. Khởi tạo Generators\n",
    "training_generator = AudioH5Generator(DATA_PATH, train_ids, batch_size=BATCH_SIZE)\n",
    "validation_generator = AudioH5Generator(DATA_PATH, val_ids, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8733a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # --- ENCODER ---\n",
    "    c1 = Conv2D(16, (3, 3), padding='same', activation='relu')(inputs)\n",
    "    c1 = BatchNormalization()(c1)\n",
    "    c1 = Conv2D(16, (3, 3), padding='same', activation='relu')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(32, (3, 3), padding='same', activation='relu')(p1)\n",
    "    c2 = BatchNormalization()(c2)\n",
    "    c2 = Conv2D(32, (3, 3), padding='same', activation='relu')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(64, (3, 3), padding='same', activation='relu')(p2)\n",
    "    c3 = BatchNormalization()(c3)\n",
    "    c3 = Conv2D(64, (3, 3), padding='same', activation='relu')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    \n",
    "    c4 = Conv2D(128, (3, 3), padding='same', activation='relu')(p3)\n",
    "    c4 = BatchNormalization()(c4)\n",
    "    c4 = Conv2D(128, (3, 3), padding='same', activation='relu')(c4)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    # --- BOTTLENECK ---\n",
    "    b = Conv2D(256, (3, 3), padding='same', activation='relu')(p4)\n",
    "    b = BatchNormalization()(b)\n",
    "    b = Conv2D(256, (3, 3), padding='same', activation='relu')(b)\n",
    "\n",
    "    # --- DECODER ---\n",
    "    u1 = UpSampling2D((2, 2))(b)\n",
    "    u1 = Concatenate()([u1, c4])\n",
    "    c5 = Conv2D(128, (3, 3), padding='same', activation='relu')(u1)\n",
    "    c5 = BatchNormalization()(c5)\n",
    "    \n",
    "    u2 = UpSampling2D((2, 2))(c5)\n",
    "    u2 = Concatenate()([u2, c3])\n",
    "    c6 = Conv2D(64, (3, 3), padding='same', activation='relu')(u2)\n",
    "    c6 = BatchNormalization()(c6)\n",
    "\n",
    "    u3 = UpSampling2D((2, 2))(c6)\n",
    "    u3 = Concatenate()([u3, c2])\n",
    "    c7 = Conv2D(32, (3, 3), padding='same', activation='relu')(u3)\n",
    "    c7 = BatchNormalization()(c7)\n",
    "    \n",
    "    u4 = UpSampling2D((2, 2))(c7)\n",
    "    u4 = Concatenate()([u4, c1])\n",
    "    c8 = Conv2D(16, (3, 3), padding='same', activation='relu')(u4)\n",
    "    c8 = BatchNormalization()(c8)\n",
    "\n",
    "    # Output (Sigmoid cho mask 0-1)\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c8)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba735ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_evaluation_audio(file_path):\n",
    "    \"\"\"Đọc file nhạc và chuẩn bị dữ liệu đầu vào cho model\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Không tìm thấy file: {file_path}\")\n",
    "        return None, None, None\n",
    "        \n",
    "    try:\n",
    "        y, _ = librosa.load(file_path, sr=SR, mono=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi đọc file evaluation: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "    # STFT & Magnitude\n",
    "    stft = librosa.stft(y, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "    mag, phase = librosa.magphase(stft)\n",
    "    \n",
    "    # Power Law Compression (Căn bậc 2 - Khớp với lúc train)\n",
    "    mag_compressed = np.sqrt(mag)\n",
    "    \n",
    "    # Cắt 1025 -> 1024 bins\n",
    "    full_mag = mag_compressed[:1024, :]\n",
    "    \n",
    "    # Chuẩn hóa\n",
    "    max_val = np.max(full_mag)\n",
    "    if max_val == 0: max_val = 1\n",
    "    full_mag_norm = full_mag / max_val\n",
    "    \n",
    "    # Chunking (Cắt thành các miếng nhỏ)\n",
    "    num_frames = full_mag_norm.shape[1]\n",
    "    pad_width = WINDOW_SIZE - (num_frames % WINDOW_SIZE)\n",
    "    if pad_width < WINDOW_SIZE:\n",
    "        full_mag_norm = np.pad(full_mag_norm, ((0,0), (0, pad_width)), mode='constant')\n",
    "        \n",
    "    chunks = []\n",
    "    num_chunks = full_mag_norm.shape[1] // WINDOW_SIZE\n",
    "    \n",
    "    for i in range(num_chunks):\n",
    "        start = i * WINDOW_SIZE\n",
    "        end = start + WINDOW_SIZE\n",
    "        chunk = full_mag_norm[:, start:end]\n",
    "        chunks.append(chunk[..., np.newaxis])\n",
    "        \n",
    "    return np.array(chunks), phase, max_val\n",
    "\n",
    "def reconstruct_from_mask(predicted_masks, phase, original_length, max_val):\n",
    "    \"\"\"Ghép các mask dự đoán lại\"\"\"\n",
    "    # 1. Ghép chunks\n",
    "    vocal_mask = np.concatenate(predicted_masks, axis=1) # (1024, Time, 1)\n",
    "    vocal_mask = vocal_mask.squeeze() # (1024, Time)\n",
    "    \n",
    "    # 2. Cắt phần padding thừa\n",
    "    vocal_mask = vocal_mask[:, :original_length]\n",
    "    \n",
    "    # 3. Bù lại dòng tần số 1025 (Pad 0 vào cuối)\n",
    "    vocal_mask = np.pad(vocal_mask, ((0,1), (0,0)), mode='constant')\n",
    "    \n",
    "    return vocal_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecd6930",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpochVisualizer(Callback):\n",
    "    def __init__(self, audio_path, output_dir):\n",
    "        super(EpochVisualizer, self).__init__()\n",
    "        self.audio_path = audio_path\n",
    "        self.output_dir = output_dir\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Visualize sau mỗi epoch\n",
    "        print(f\"\\nĐang visualize kết quả epoch {epoch+1}...\")\n",
    "        \n",
    "        # 1. Preprocess\n",
    "        chunks, phase, max_val = preprocess_evaluation_audio(self.audio_path)\n",
    "        if chunks is None: return\n",
    "\n",
    "        # 2. Predict\n",
    "        predicted_masks = self.model.predict(chunks, batch_size=16, verbose=0)\n",
    "        \n",
    "        # 3. Reconstruct Mask\n",
    "        original_length = phase.shape[1]\n",
    "        mask = reconstruct_from_mask(predicted_masks, phase, original_length, max_val)\n",
    "        \n",
    "        # 4. Visualize bằng Librosa\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Vẽ Mask dự đoán\n",
    "        plt.subplot(1, 2, 1)\n",
    "        librosa.display.specshow(mask, sr=SR, x_axis='time', y_axis='hz', cmap='magma')\n",
    "        plt.title(f\"Predicted Vocal Mask - Epoch {epoch+1}\")\n",
    "        plt.colorbar(format='%+2.0f')\n",
    "        \n",
    "        # Vẽ Spectrogram kết quả (Vocal đã tách)\n",
    "        # Lấy lại Magnitude gốc để hiển thị\n",
    "        y, _ = librosa.load(self.audio_path, sr=SR)\n",
    "        S_full, _ = librosa.magphase(librosa.stft(y, n_fft=N_FFT, hop_length=HOP_LENGTH))\n",
    "        S_vocal = S_full * mask # Áp dụng mask\n",
    "        S_db = librosa.amplitude_to_db(S_vocal, ref=np.max)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        librosa.display.specshow(S_db, sr=SR, x_axis='time', y_axis='log', cmap='magma')\n",
    "        plt.title(f\"Separated Vocal Spectrogram - Epoch {epoch+1}\")\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # 5. Lưu ảnh\n",
    "        save_path = os.path.join(self.output_dir, f\"epoch_{epoch+1:03d}.png\")\n",
    "        plt.savefig(save_path)\n",
    "        plt.close() # Đóng plot\n",
    "        print(f\"Đã lưu ảnh visualize tại: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
