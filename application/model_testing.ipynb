{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df3925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a278f447",
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 44100\n",
    "N_FFT = 2048\n",
    "HOP_LENGTH = 512\n",
    "WINDOW_SIZE = 128 # Kích thước cửa sổ bạn đã chọn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb118001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_audio(audio_path, model, output_dir=\"results\"):\n",
    "    print(f\"Đang xử lý: {audio_path}...\")\n",
    "    \n",
    "    # 1. Load âm thanh\n",
    "    y, sr = librosa.load(audio_path, sr=SR)\n",
    "    \n",
    "    # 2. STFT\n",
    "    stft = librosa.stft(y, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "    mag, phase = librosa.magphase(stft)\n",
    "    \n",
    "    # Lưu lại kích thước gốc để lát cắt về đúng size này\n",
    "    original_length = mag.shape[1]\n",
    "    \n",
    "    # 3. Tiền xử lý Shape cho Model\n",
    "    full_mag = mag[:1024, :] \n",
    "    \n",
    "    # Chuẩn hóa\n",
    "    max_val = np.max(full_mag)\n",
    "    if max_val == 0: max_val = 1 # Tránh lỗi chia cho 0\n",
    "    full_mag_norm = full_mag / max_val\n",
    "    \n",
    "    # 4. Padding (Đắp thêm cho đủ chia hết WINDOW_SIZE)\n",
    "    # CHỈ ĐẮP CHO INPUT CỦA MODEL, KHÔNG ĐẮP CHO PHASE GỐC\n",
    "    num_frames = full_mag_norm.shape[1]\n",
    "    pad_width = WINDOW_SIZE - (num_frames % WINDOW_SIZE)\n",
    "    \n",
    "    if pad_width < WINDOW_SIZE:\n",
    "        full_mag_norm = np.pad(full_mag_norm, ((0,0), (0, pad_width)), mode='constant')\n",
    "        # Lỗi cũ nằm ở đây: Ta đã lỡ tay pad luôn cả phase. \n",
    "        # Bây giờ ta KHÔNG pad phase nữa, hoặc dùng biến tạm nếu cần.\n",
    "        \n",
    "    # 5. Cắt Chunk\n",
    "    chunks = []\n",
    "    num_chunks = full_mag_norm.shape[1] // WINDOW_SIZE\n",
    "    \n",
    "    for i in range(num_chunks):\n",
    "        start = i * WINDOW_SIZE\n",
    "        end = start + WINDOW_SIZE\n",
    "        chunk = full_mag_norm[:, start:end]\n",
    "        chunks.append(chunk[..., np.newaxis])\n",
    "        \n",
    "    chunks = np.array(chunks)\n",
    "    \n",
    "    # 6. DỰ ĐOÁN\n",
    "    print(\"Đang chạy mô hình để tách...\")\n",
    "    predicted_masks = model.predict(chunks, batch_size=16, verbose=1)\n",
    "    \n",
    "    # 7. Ghép lại (Concatenate)\n",
    "    vocal_mask = np.concatenate(predicted_masks, axis=1)\n",
    "    vocal_mask = vocal_mask.squeeze()\n",
    "    \n",
    "    # Bù lại dòng tần số 1025\n",
    "    vocal_mask = np.pad(vocal_mask, ((0,1), (0,0)), mode='constant')\n",
    "    \n",
    "    # --- QUAN TRỌNG: Cắt về đúng kích thước gốc ---\n",
    "    # Cắt bỏ phần padding thừa lúc nãy để khớp với Phase gốc\n",
    "    vocal_mask = vocal_mask[:, :original_length]\n",
    "    \n",
    "    # 8. Tái tạo âm thanh\n",
    "    inst_mask = 1.0 - vocal_mask\n",
    "    \n",
    "    # Nhân mask với Magnitude gốc\n",
    "    mag_vocal = mag * vocal_mask\n",
    "    mag_inst = mag * inst_mask\n",
    "    \n",
    "    # Kết hợp với Phase gốc (Phase chưa bị thay đổi kích thước)\n",
    "    stft_vocal = mag_vocal * phase\n",
    "    stft_inst = mag_inst * phase\n",
    "    \n",
    "    # iSTFT\n",
    "    y_vocal = librosa.istft(stft_vocal, hop_length=HOP_LENGTH)\n",
    "    y_inst = librosa.istft(stft_inst, hop_length=HOP_LENGTH)\n",
    "    \n",
    "    # 9. Lưu file\n",
    "    import os\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    file_name = os.path.basename(audio_path).split('.')[0]\n",
    "    vocal_path = os.path.join(output_dir, f\"{file_name}_vocal.wav\")\n",
    "    inst_path = os.path.join(output_dir, f\"{file_name}_instrumental.wav\")\n",
    "    \n",
    "    sf.write(vocal_path, y_vocal, SR)\n",
    "    sf.write(inst_path, y_inst, SR)\n",
    "    \n",
    "    print(f\"Xong! Đã lưu tại:\\n - {vocal_path}\\n - {inst_path}\")\n",
    "    return y_vocal, y_inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e49f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_separation(mix, vocal, inst, sr=44100):\n",
    "    \"\"\"\n",
    "    Hàm vẽ so sánh 3 track: Mix, Vocal, Instrumental\n",
    "    Input có thể là đường dẫn file (str) hoặc mảng numpy (array)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Load dữ liệu nếu input là đường dẫn file\n",
    "    if isinstance(mix, str): mix, _ = librosa.load(mix, sr=sr)\n",
    "    if isinstance(vocal, str): vocal, _ = librosa.load(vocal, sr=sr)\n",
    "    if isinstance(inst, str): inst, _ = librosa.load(inst, sr=sr)\n",
    "\n",
    "    # --- PHẦN 1: WAVEFORM (DẠNG SÓNG) ---\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    plt.subplot(3, 1, 1)\n",
    "    librosa.display.waveshow(mix, sr=sr, color='gray', alpha=0.7)\n",
    "    plt.title(\"1. Original Mixture (Bản gốc)\")\n",
    "    \n",
    "    plt.subplot(3, 1, 2)\n",
    "    librosa.display.waveshow(vocal, sr=sr, color='blue', alpha=0.7)\n",
    "    plt.title(\"2. Extracted Vocal (Giọng hát tách được)\")\n",
    "    plt.ylim(plt.ylim()) # Giữ tỉ lệ trục Y giống bản gốc để dễ so sánh\n",
    "    \n",
    "    plt.subplot(3, 1, 3)\n",
    "    librosa.display.waveshow(inst, sr=sr, color='green', alpha=0.7)\n",
    "    plt.title(\"3. Extracted Instrumental (Nhạc nền tách được)\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # --- PHẦN 2: SPECTROGRAM (QUAN TRỌNG HƠN) ---\n",
    "    # Chuyển sang Log-Mel Spectrogram để nhìn rõ tần số như mắt người/tai người\n",
    "    def compute_spec(y):\n",
    "        # Tính STFT -> Lấy độ lớn -> Chuyển sang dB (Decibel)\n",
    "        D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "        return D\n",
    "\n",
    "    specs = [compute_spec(mix), compute_spec(vocal), compute_spec(inst)]\n",
    "    titles = [\"Original Spectrogram\", \"Vocal Spectrogram\", \"Instrumental Spectrogram\"]\n",
    "    \n",
    "    plt.figure(figsize=(15, 6))\n",
    "    for i, (D, title) in enumerate(zip(specs, titles)):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log', cmap='magma')\n",
    "        plt.title(title)\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c666149a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang xử lý: ..\\media_files\\separated_audio\\Tobenai Tsubasa - Lily Chou-Chou.mp3...\n",
      "Đang chạy mô hình để tách...\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 326ms/step\n",
      "Xong! Đã lưu tại:\n",
      " - results\\Tobenai Tsubasa - Lily Chou-Chou_vocal.wav\n",
      " - results\\Tobenai Tsubasa - Lily Chou-Chou_instrumental.wav\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 1. Load model đã train\n",
    "# Thay đường dẫn tới file .keras tốt nhất của bạn\n",
    "model_path = r\"../best_unet_vocal.keras\"\n",
    "model = load_model(model_path)\n",
    "\n",
    "# 2. Chọn một bài nhạc bất kỳ để test\n",
    "test_audio = r\"..\\media_files\\separated_audio\\Tobenai Tsubasa - Lily Chou-Chou.mp3\" # Thay bằng file nhạc của bạn\n",
    "\n",
    "# 3. Gọi hàm\n",
    "vocal, inst = separate_audio(test_audio, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "421c92a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mvisualize_separation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_audio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mvisualize_separation\u001b[39m\u001b[34m(mix, vocal, inst, sr)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inst, \u001b[38;5;28mstr\u001b[39m): inst, _ = librosa.load(inst, sr=sr)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# --- PHẦN 1: WAVEFORM (DẠNG SÓNG) ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mplt\u001b[49m.figure(figsize=(\u001b[32m15\u001b[39m, \u001b[32m8\u001b[39m))\n\u001b[32m     15\u001b[39m plt.subplot(\u001b[32m3\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m     16\u001b[39m librosa.display.waveshow(mix, sr=sr, color=\u001b[33m'\u001b[39m\u001b[33mgray\u001b[39m\u001b[33m'\u001b[39m, alpha=\u001b[32m0.7\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "visualize_separation(test_audio, vocal, inst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
